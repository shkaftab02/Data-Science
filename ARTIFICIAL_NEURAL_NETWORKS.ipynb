{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/Alphabets_data.csv')\n",
        "\n",
        "print(data.head())\n",
        "print(data.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Em910muegg-N",
        "outputId": "0f24278b-720c-49b5-dc91-e8d405dffabd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
            "0      T     2     8      3       5      1     8    13      0      6      6   \n",
            "1      I     5    12      3       7      2    10     5      5      4     13   \n",
            "2      D     4    11      6       8      6    10     6      2      6     10   \n",
            "3      N     7    11      6       6      3     5     9      4      6      4   \n",
            "4      G     2     1      3       1      1     8     6      6      6      6   \n",
            "\n",
            "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
            "0      10       8      0       8      0       8  \n",
            "1       3       9      2       8      4      10  \n",
            "2       3       7      3       7      3       9  \n",
            "3       4      10      6      10      2       8  \n",
            "4       5       9      1       7      5      10  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   letter  20000 non-null  object\n",
            " 1   xbox    20000 non-null  int64 \n",
            " 2   ybox    20000 non-null  int64 \n",
            " 3   width   20000 non-null  int64 \n",
            " 4   height  20000 non-null  int64 \n",
            " 5   onpix   20000 non-null  int64 \n",
            " 6   xbar    20000 non-null  int64 \n",
            " 7   ybar    20000 non-null  int64 \n",
            " 8   x2bar   20000 non-null  int64 \n",
            " 9   y2bar   20000 non-null  int64 \n",
            " 10  xybar   20000 non-null  int64 \n",
            " 11  x2ybar  20000 non-null  int64 \n",
            " 12  xy2bar  20000 non-null  int64 \n",
            " 13  xedge   20000 non-null  int64 \n",
            " 14  xedgey  20000 non-null  int64 \n",
            " 15  yedge   20000 non-null  int64 \n",
            " 16  yedgex  20000 non-null  int64 \n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 2.6+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.drop(columns='letter')\n",
        "y = data['letter']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}, Test set size: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MndPEGIXgjcM",
        "outputId": "856b69db-6302-4270-f21f-ea202e1b622c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (16000, 16), Test set size: (4000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "X = data.drop(columns='letter')\n",
        "y = data['letter']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Hidden layer 1\n",
        "model.add(Dense(32, activation='relu'))  # Hidden layer 2\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Output layer (size based on number of unique classes)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train_cat, epochs=50, batch_size=32, validation_data=(X_test, y_test_cat))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test_cat)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IB32HtuMglSj",
        "outputId": "5c50e109-04d5-4007-a5bc-2f2ca2f0502b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1429 - loss: 3.0438 - val_accuracy: 0.4322 - val_loss: 2.0015\n",
            "Epoch 2/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4789 - loss: 1.8534 - val_accuracy: 0.5683 - val_loss: 1.5207\n",
            "Epoch 3/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 1.4690 - val_accuracy: 0.6463 - val_loss: 1.2943\n",
            "Epoch 4/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 1.2666 - val_accuracy: 0.6895 - val_loss: 1.1622\n",
            "Epoch 5/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 1.1615 - val_accuracy: 0.7075 - val_loss: 1.0767\n",
            "Epoch 6/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7081 - loss: 1.0814 - val_accuracy: 0.7278 - val_loss: 1.0281\n",
            "Epoch 7/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 1.0153 - val_accuracy: 0.7340 - val_loss: 0.9774\n",
            "Epoch 8/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.9857 - val_accuracy: 0.7535 - val_loss: 0.9390\n",
            "Epoch 9/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.9405 - val_accuracy: 0.7533 - val_loss: 0.9189\n",
            "Epoch 10/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7580 - loss: 0.9135 - val_accuracy: 0.7655 - val_loss: 0.8760\n",
            "Epoch 11/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7703 - loss: 0.8663 - val_accuracy: 0.7738 - val_loss: 0.8433\n",
            "Epoch 12/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.8403 - val_accuracy: 0.7835 - val_loss: 0.8178\n",
            "Epoch 13/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.8230 - val_accuracy: 0.7742 - val_loss: 0.8382\n",
            "Epoch 14/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 0.8148 - val_accuracy: 0.7835 - val_loss: 0.7867\n",
            "Epoch 15/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7807 - loss: 0.7820 - val_accuracy: 0.7872 - val_loss: 0.7803\n",
            "Epoch 16/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.7818 - val_accuracy: 0.7900 - val_loss: 0.7548\n",
            "Epoch 17/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.7368 - val_accuracy: 0.7990 - val_loss: 0.7362\n",
            "Epoch 18/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7926 - loss: 0.7466 - val_accuracy: 0.8018 - val_loss: 0.7233\n",
            "Epoch 19/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.7232 - val_accuracy: 0.7977 - val_loss: 0.7149\n",
            "Epoch 20/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.7000 - val_accuracy: 0.8015 - val_loss: 0.6972\n",
            "Epoch 21/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.6830 - val_accuracy: 0.8060 - val_loss: 0.6887\n",
            "Epoch 22/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.6708 - val_accuracy: 0.8163 - val_loss: 0.6651\n",
            "Epoch 23/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8082 - loss: 0.6553 - val_accuracy: 0.8160 - val_loss: 0.6601\n",
            "Epoch 24/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.6552 - val_accuracy: 0.8125 - val_loss: 0.6620\n",
            "Epoch 25/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.6299 - val_accuracy: 0.8215 - val_loss: 0.6325\n",
            "Epoch 26/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.6364 - val_accuracy: 0.8207 - val_loss: 0.6331\n",
            "Epoch 27/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.6140 - val_accuracy: 0.8148 - val_loss: 0.6244\n",
            "Epoch 28/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.6069 - val_accuracy: 0.8217 - val_loss: 0.6106\n",
            "Epoch 29/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.5776 - val_accuracy: 0.8328 - val_loss: 0.5915\n",
            "Epoch 30/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.5712 - val_accuracy: 0.8315 - val_loss: 0.5943\n",
            "Epoch 31/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8288 - loss: 0.5741 - val_accuracy: 0.8330 - val_loss: 0.5655\n",
            "Epoch 32/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.5580 - val_accuracy: 0.8292 - val_loss: 0.5724\n",
            "Epoch 33/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.5603 - val_accuracy: 0.8370 - val_loss: 0.5544\n",
            "Epoch 34/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.5507 - val_accuracy: 0.8418 - val_loss: 0.5460\n",
            "Epoch 35/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.5354 - val_accuracy: 0.8478 - val_loss: 0.5294\n",
            "Epoch 36/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.5192 - val_accuracy: 0.8422 - val_loss: 0.5402\n",
            "Epoch 37/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.5239 - val_accuracy: 0.8450 - val_loss: 0.5257\n",
            "Epoch 38/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.5214 - val_accuracy: 0.8455 - val_loss: 0.5328\n",
            "Epoch 39/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.5175 - val_accuracy: 0.8475 - val_loss: 0.5223\n",
            "Epoch 40/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.4949 - val_accuracy: 0.8487 - val_loss: 0.5031\n",
            "Epoch 41/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.5016 - val_accuracy: 0.8543 - val_loss: 0.4988\n",
            "Epoch 42/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.4553 - val_accuracy: 0.8570 - val_loss: 0.4889\n",
            "Epoch 43/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.4889 - val_accuracy: 0.8587 - val_loss: 0.4807\n",
            "Epoch 44/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.4585 - val_accuracy: 0.8560 - val_loss: 0.4836\n",
            "Epoch 45/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8592 - loss: 0.4679 - val_accuracy: 0.8585 - val_loss: 0.4791\n",
            "Epoch 46/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.4610 - val_accuracy: 0.8590 - val_loss: 0.4792\n",
            "Epoch 47/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.4511 - val_accuracy: 0.8622 - val_loss: 0.4719\n",
            "Epoch 48/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.4511 - val_accuracy: 0.8665 - val_loss: 0.4502\n",
            "Epoch 49/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.4364 - val_accuracy: 0.8648 - val_loss: 0.4534\n",
            "Epoch 50/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.4341 - val_accuracy: 0.8668 - val_loss: 0.4504\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8707 - loss: 0.4392  \n",
            "Test accuracy: 86.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "def create_model(neurons=64, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons, input_dim=X_train.shape[1], activation=activation))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "param_grid = {\n",
        "    'neurons': [32, 64, 128],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "}\n",
        "def grid_search():\n",
        "    best_score = 0\n",
        "    best_params = None\n",
        "\n",
        "    for neurons in param_grid['neurons']:\n",
        "        for activation in param_grid['activation']:\n",
        "            model = create_model(neurons=neurons, activation=activation)\n",
        "            history = model.fit(X_train, y_train_cat, epochs=50, batch_size=32, validation_data=(X_test, y_test_cat), verbose=0)\n",
        "            score = model.evaluate(X_test, y_test_cat, verbose=0)[1]  # Use accuracy as score\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = {'neurons': neurons, 'activation': activation}\n",
        "\n",
        "    return best_params, best_score\n",
        "best_params, best_score = grid_search()\n",
        "print(f\"Best Hyperparameters: {best_params} with accuracy {best_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IE1iR2ignFD",
        "outputId": "160904c5-bcc4-43ee-cc7d-efd23bce1b26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'neurons': 64, 'activation': 'tanh'} with accuracy 0.8867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "print(classification_report(y_test, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SAmYOvGgqH0",
        "outputId": "fd8a5cd2-a6fa-4be8-bc3c-544f95482a5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.95      0.86       149\n",
            "           1       0.89      0.82      0.85       153\n",
            "           2       0.94      0.80      0.87       137\n",
            "           3       0.84      0.90      0.87       156\n",
            "           4       0.89      0.80      0.84       141\n",
            "           5       0.79      0.89      0.84       140\n",
            "           6       0.80      0.81      0.80       160\n",
            "           7       0.78      0.67      0.72       144\n",
            "           8       0.91      0.85      0.88       146\n",
            "           9       0.89      0.89      0.89       149\n",
            "          10       0.73      0.88      0.80       130\n",
            "          11       0.87      0.87      0.87       155\n",
            "          12       0.93      0.93      0.93       168\n",
            "          13       0.90      0.87      0.89       151\n",
            "          14       0.79      0.86      0.82       145\n",
            "          15       0.97      0.81      0.88       173\n",
            "          16       0.86      0.88      0.87       166\n",
            "          17       0.78      0.84      0.81       160\n",
            "          18       0.83      0.87      0.85       171\n",
            "          19       0.96      0.88      0.92       163\n",
            "          20       0.93      0.90      0.92       183\n",
            "          21       0.91      0.92      0.91       158\n",
            "          22       0.94      0.95      0.95       148\n",
            "          23       0.87      0.92      0.89       154\n",
            "          24       0.87      0.86      0.86       168\n",
            "          25       0.92      0.90      0.91       132\n",
            "\n",
            "    accuracy                           0.87      4000\n",
            "   macro avg       0.87      0.87      0.87      4000\n",
            "weighted avg       0.87      0.87      0.87      4000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}